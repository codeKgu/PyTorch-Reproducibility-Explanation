{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Loading the Data\n",
    "We use the CIFAR dataset as an example. We download our training and validation dataset splits and wrap a DataLoader object around them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "transforms = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5), (0.5))])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10('./data', train=True,\n",
    "                                       download=True,\n",
    "                                       transform=transforms)\n",
    "train_loader = DataLoader(train_set, batch_size=4, shuffle=False)\n",
    "\n",
    "# treat the test dataset as a validation set for this example\n",
    "validation_set = torchvision.datasets.CIFAR10('./data', train=False,\n",
    "                                            download=True,\n",
    "                                            transform=transforms)\n",
    "validation_loader = DataLoader(validation_set, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining our PyTorch Model\n",
    "Our PyTorch model will be a simple convolutional neural network. Note the choice of including the dropout layer after the first fully connected layer. This will be important later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, dropout=True):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        \n",
    "        self.dropout1 = nn.Dropout(0.2) if dropout else None\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        if self.dropout1 is not None:\n",
    "            x = self.dropout1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Experiment Running\n",
    "For each experiment we will run on two epochs and observe the training loss. We will generate the same initial seed to hopefully ensure reproducibility. We also allow different validation functions to explore how different changes affect reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# use a validation func to allow us to easily define different ways of validation for illustrative purposes \n",
    "def train(net, train_loader, validation_loader, optimizer, criterion, validation_func, num_epochs=2):\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "        net.train()\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                print('[Epoch %d, Iter %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "            \n",
    "        if validation_func is not None:\n",
    "            validation_func(net, validation_loader, epoch)\n",
    "        print('')\n",
    "    \n",
    "    print('Finished Training')\n",
    "\n",
    "\n",
    "\n",
    "def validation(net, validation_dataloader, epoch):\n",
    "    net.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(validation_dataloader, 0):\n",
    "            inputs, labels = data\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "    print('Val [Epoch %d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / len(validation_dataloader) ))\n",
    "\n",
    "SEED = 2147483647"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Training With Validation vs. Without"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Training With Validation ========\n",
      "[Epoch 1, Iter  2000] loss: 2.131\n",
      "[Epoch 1, Iter  4000] loss: 1.837\n",
      "[Epoch 1, Iter  6000] loss: 1.676\n",
      "[Epoch 1, Iter  8000] loss: 1.588\n",
      "[Epoch 1, Iter 10000] loss: 1.567\n",
      "[Epoch 1, Iter 12000] loss: 1.532\n",
      "Val [Epoch 1,  2500] loss: 1.453\n",
      "\n",
      "[Epoch 2, Iter  2000] loss: 1.465\n",
      "[Epoch 2, Iter  4000] loss: 1.457\n",
      "[Epoch 2, Iter  6000] loss: 1.411\n",
      "[Epoch 2, Iter  8000] loss: 1.365\n",
      "[Epoch 2, Iter 10000] loss: 1.388\n",
      "[Epoch 2, Iter 12000] loss: 1.359\n",
      "Val [Epoch 2,  2500] loss: 1.277\n",
      "\n",
      "Finished Training\n",
      "======== Training Without Validation ========\n",
      "[Epoch 1, Iter  2000] loss: 2.131\n",
      "[Epoch 1, Iter  4000] loss: 1.837\n",
      "[Epoch 1, Iter  6000] loss: 1.676\n",
      "[Epoch 1, Iter  8000] loss: 1.588\n",
      "[Epoch 1, Iter 10000] loss: 1.567\n",
      "[Epoch 1, Iter 12000] loss: 1.532\n",
      "\n",
      "[Epoch 2, Iter  2000] loss: 1.463\n",
      "[Epoch 2, Iter  4000] loss: 1.458\n",
      "[Epoch 2, Iter  6000] loss: 1.410\n",
      "[Epoch 2, Iter  8000] loss: 1.361\n",
      "[Epoch 2, Iter 10000] loss: 1.386\n",
      "[Epoch 2, Iter 12000] loss: 1.359\n",
      "\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "print('======== Training With Validation ========')\n",
    "torch.manual_seed(SEED)\n",
    "net = Net(dropout=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "train(net, train_loader, validation_loader, optimizer, criterion, validation_func=validation)\n",
    "\n",
    "print('======== Training Without Validation ========')\n",
    "torch.manual_seed(SEED)\n",
    "net = Net(dropout=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "train(net, train_loader, validation_loader, optimizer, criterion, validation_func=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Training Without Dropout With and Without Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('======== Training With Validation without Dropout ========')\n",
    "torch.manual_seed(SEED)\n",
    "net = Net(dropout=False)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "train(net, train_loader, validation_loader, optimizer, criterion, validation_func=validation)\n",
    "\n",
    "print('======== Training Without Validation without Dropout ========')\n",
    "torch.manual_seed(SEED)\n",
    "net = Net(dropout=False)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "train(net, train_loader, validation_loader, optimizer, criterion, validation_func=None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training With Validation Skipping Forward Pass vs Without Validation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def validation_without_model(net, validation_dataloader, epoch):\n",
    "    net.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(validation_dataloader, 0):\n",
    "            break\n",
    "            inputs, labels = data\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "    print('Val [Epoch %d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / len(validation_dataloader) ))\n",
    "print('======== Training With Validation Skip Forward Pass ========')\n",
    "torch.manual_seed(SEED)\n",
    "net = Net(dropout=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "train(net, train_loader, validation_loader, optimizer, criterion, validation_func=validation_without_model)\n",
    "\n",
    "print('======== Training Without Validation ========')\n",
    "torch.manual_seed(SEED)\n",
    "net = Net(dropout=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "train(net, train_loader, validation_loader, optimizer, criterion, validation_func=None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training With Validation Ensuring RNG State vs Without"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Training With Validation without Dropout ========\n",
      "[Epoch 1, Iter  2000] loss: 2.111\n",
      "[Epoch 1, Iter  4000] loss: 1.805\n",
      "[Epoch 1, Iter  6000] loss: 1.639\n",
      "[Epoch 1, Iter  8000] loss: 1.546\n",
      "[Epoch 1, Iter 10000] loss: 1.529\n",
      "[Epoch 1, Iter 12000] loss: 1.478\n",
      "Val [Epoch 1,  2500] loss: 1.418\n",
      "\n",
      "[Epoch 2, Iter  2000] loss: 1.413\n",
      "[Epoch 2, Iter  4000] loss: 1.406\n",
      "[Epoch 2, Iter  6000] loss: 1.346\n",
      "[Epoch 2, Iter  8000] loss: 1.312\n",
      "[Epoch 2, Iter 10000] loss: 1.325\n",
      "[Epoch 2, Iter 12000] loss: 1.290\n",
      "Val [Epoch 2,  2500] loss: 1.298\n",
      "\n",
      "Finished Training\n",
      "======== Training Without Validation without Dropout ========\n",
      "[Epoch 1, Iter  2000] loss: 2.111\n",
      "[Epoch 1, Iter  4000] loss: 1.805\n",
      "[Epoch 1, Iter  6000] loss: 1.639\n",
      "[Epoch 1, Iter  8000] loss: 1.546\n",
      "[Epoch 1, Iter 10000] loss: 1.529\n",
      "[Epoch 1, Iter 12000] loss: 1.478\n",
      "\n",
      "[Epoch 2, Iter  2000] loss: 1.413\n",
      "[Epoch 2, Iter  4000] loss: 1.406\n",
      "[Epoch 2, Iter  6000] loss: 1.346\n",
      "[Epoch 2, Iter  8000] loss: 1.312\n",
      "[Epoch 2, Iter 10000] loss: 1.325\n",
      "[Epoch 2, Iter 12000] loss: 1.290\n",
      "\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "def validation_ensure_rng_state(net, validation_dataloader, epoch):\n",
    "    net.eval()\n",
    "    running_loss = 0.0\n",
    "    state = torch.get_rng_state()\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(validation_dataloader, 0):\n",
    "            inputs, labels = data\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "    print('Val [Epoch %d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / len(validation_dataloader) ))\n",
    "    torch.set_rng_state(state)\n",
    "    \n",
    "print('======== Training With Validation Ensure RNG State ========')\n",
    "torch.manual_seed(SEED)\n",
    "net = Net(dropout=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "train(net, train_loader, validation_loader, optimizer, criterion, validation_func=validation_ensure_rng_state)\n",
    "\n",
    "print('======== Training Without Validation ========')\n",
    "torch.manual_seed(SEED)\n",
    "net = Net(dropout=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "train(net, train_loader, validation_loader, optimizer, criterion, validation_func=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training With Validation Skipping Forward Pass vs Without Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Training With Validation Skip Forward Pass ========\n",
      "[Epoch 1, Iter  2000] loss: 2.131\n",
      "[Epoch 1, Iter  4000] loss: 1.837\n",
      "[Epoch 1, Iter  6000] loss: 1.676\n",
      "[Epoch 1, Iter  8000] loss: 1.588\n",
      "[Epoch 1, Iter 10000] loss: 1.567\n",
      "[Epoch 1, Iter 12000] loss: 1.532\n",
      "Val [Epoch 1,     1] loss: 0.000\n",
      "\n",
      "[Epoch 2, Iter  2000] loss: 1.465\n",
      "[Epoch 2, Iter  4000] loss: 1.457\n",
      "[Epoch 2, Iter  6000] loss: 1.411\n",
      "[Epoch 2, Iter  8000] loss: 1.365\n",
      "[Epoch 2, Iter 10000] loss: 1.388\n",
      "[Epoch 2, Iter 12000] loss: 1.359\n",
      "Val [Epoch 2,     1] loss: 0.000\n",
      "\n",
      "Finished Training\n",
      "======== Training Without Validation ========\n",
      "[Epoch 1, Iter  2000] loss: 2.131\n",
      "[Epoch 1, Iter  4000] loss: 1.837\n",
      "[Epoch 1, Iter  6000] loss: 1.676\n",
      "[Epoch 1, Iter  8000] loss: 1.588\n",
      "[Epoch 1, Iter 10000] loss: 1.567\n",
      "[Epoch 1, Iter 12000] loss: 1.532\n",
      "\n",
      "[Epoch 2, Iter  2000] loss: 1.463\n",
      "[Epoch 2, Iter  4000] loss: 1.458\n",
      "[Epoch 2, Iter  6000] loss: 1.410\n",
      "[Epoch 2, Iter  8000] loss: 1.361\n",
      "[Epoch 2, Iter 10000] loss: 1.386\n",
      "[Epoch 2, Iter 12000] loss: 1.359\n",
      "\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "def validation_without_model(net, validation_dataloader, epoch):\n",
    "    net.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(validation_dataloader, 0):\n",
    "            break\n",
    "            inputs, labels = data\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "    print('Val [Epoch %d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / len(validation_dataloader) ))\n",
    "print('======== Training With Validation Skip Forward Pass ========')\n",
    "torch.manual_seed(SEED)\n",
    "net = Net(dropout=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "train(net, train_loader, validation_loader, optimizer, criterion, validation_func=validation_without_model)\n",
    "\n",
    "print('======== Training Without Validation ========')\n",
    "torch.manual_seed(SEED)\n",
    "net = Net(dropout=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "train(net, train_loader, validation_loader, optimizer, criterion, validation_func=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training With Validation Ensuring RNG State vs Without"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Training With Validation Ensure RNG State ========\n",
      "[Epoch 1, Iter  2000] loss: 2.131\n",
      "[Epoch 1, Iter  4000] loss: 1.837\n",
      "[Epoch 1, Iter  6000] loss: 1.676\n",
      "[Epoch 1, Iter  8000] loss: 1.588\n",
      "[Epoch 1, Iter 10000] loss: 1.567\n",
      "[Epoch 1, Iter 12000] loss: 1.532\n",
      "Val [Epoch 1,  2500] loss: 1.453\n",
      "\n",
      "[Epoch 2, Iter  2000] loss: 1.463\n",
      "[Epoch 2, Iter  4000] loss: 1.458\n",
      "[Epoch 2, Iter  6000] loss: 1.410\n",
      "[Epoch 2, Iter  8000] loss: 1.361\n",
      "[Epoch 2, Iter 10000] loss: 1.386\n",
      "[Epoch 2, Iter 12000] loss: 1.359\n",
      "Val [Epoch 2,  2500] loss: 1.273\n",
      "\n",
      "Finished Training\n",
      "======== Training Without Validation ========\n",
      "[Epoch 1, Iter  2000] loss: 2.131\n",
      "[Epoch 1, Iter  4000] loss: 1.837\n",
      "[Epoch 1, Iter  6000] loss: 1.676\n",
      "[Epoch 1, Iter  8000] loss: 1.588\n",
      "[Epoch 1, Iter 10000] loss: 1.567\n",
      "[Epoch 1, Iter 12000] loss: 1.532\n",
      "\n",
      "[Epoch 2, Iter  2000] loss: 1.463\n",
      "[Epoch 2, Iter  4000] loss: 1.458\n",
      "[Epoch 2, Iter  6000] loss: 1.410\n",
      "[Epoch 2, Iter  8000] loss: 1.361\n",
      "[Epoch 2, Iter 10000] loss: 1.386\n",
      "[Epoch 2, Iter 12000] loss: 1.359\n",
      "\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "def validation_ensure_rng_state(net, validation_dataloader, epoch):\n",
    "    net.eval()\n",
    "    running_loss = 0.0\n",
    "    state = torch.get_rng_state()\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(validation_dataloader, 0):\n",
    "            inputs, labels = data\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "    print('Val [Epoch %d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / len(validation_dataloader) ))\n",
    "    torch.set_rng_state(state)\n",
    "    \n",
    "print('======== Training With Validation Ensure RNG State ========')\n",
    "torch.manual_seed(SEED)\n",
    "net = Net(dropout=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "train(net, train_loader, validation_loader, optimizer, criterion, validation_func=validation_ensure_rng_state)\n",
    "\n",
    "print('======== Training Without Validation ========')\n",
    "torch.manual_seed(SEED)\n",
    "net = Net(dropout=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "train(net, train_loader, validation_loader, optimizer, criterion, validation_func=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}